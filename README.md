# ğŸ›¡ï¸ Content Moderation Service

![Python](https://img.shields.io/badge/Python-3.12+-blue.svg) ![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg) ![Kafka](https://img.shields.io/badge/Kafka-Enabled-orange.svg)

**A comprehensive AI-powered content moderation service built with FastAPI, providing advanced text analysis capabilities with support for multiple languages and intelligent processing.**

**Quick Navigation:** [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“– Documentation](#-api-documentation) â€¢ [ğŸ”§ Configuration](#-configuration) â€¢ [ğŸ³ Docker](#-docker-deployment)

---

## ğŸ“‹ Table of Contents

- [âœ¨ Features](#-features)
- [ğŸ—ï¸ Architecture](#-architecture)
- [ğŸ“‹ Prerequisites](#-prerequisites)
- [ğŸš€ Quick Start](#-quick-start)
- [âš™ï¸ Configuration](#-configuration)
- [ğŸ“– API Documentation](#-api-documentation)
- [ğŸ§ª AI Models](#-ai-models)
- [ğŸ“Š API Examples](#-api-examples)
- [ğŸ“¡ Kafka Integration](#-kafka-integration)
- [ğŸ” Monitoring](#-monitoring)
- [ğŸ³ Docker Deployment](#-docker-deployment)
- [ğŸ¤ Contributing](#-contributing)

---

## âœ¨ Features

### ğŸ¯ Text Profanity Detection
- **Transformer-Based Models**: English (toxic-bert) & Indic (MuRIL)
- **100+ Languages**: XLM-RoBERTa language detection
- **Code-Mixed Support**: Hinglish, Spanglish, etc.
- **Smart Chunking**: Sliding window for long texts
- **Result Aggregation**: Priority-based & majority voting

### ğŸ” Language Detection
- **97.9% Accuracy**: XLM-RoBERTa powered
- **Real-time Processing**: Fast language identification
- **Mixed Languages**: Code-switched text support
- **Script Analysis**: Character distribution analysis

### âš™ï¸ Advanced Processing
- **Automatic Chunking**: Intelligent text segmentation
- **Token Management**: Configurable sizes & overlap
- **GPU Acceleration**: Transformer model optimization
- **Rate Limiting**: Per-endpoint controls

### ğŸ“¡ Event Streaming
- **Kafka Integration**: Real-time event emission
- **Custom Topics**: Configurable event routing
- **Retry Logic**: Reliable message delivery
- **Monitoring**: Built-in observability

---

## ğŸ—ï¸ Architecture

### ğŸ“ Project Structure

```
src/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ v1/                           # API Controllers
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ language_controller.py    # Language detection endpoints
â”‚       â””â”€â”€ profanity_controller.py   # Profanity detection endpoints
â”œâ”€â”€ services/                         # Business Logic
â”‚   â”œâ”€â”€ kafka/                        # Kafka Integration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ kafka_service.py          # Kafka producer and messaging
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ language_detection_service.py # Language identification
â”‚   â”œâ”€â”€ text_chunking_service.py      # Text segmentation
â”‚   â””â”€â”€ text_profanity_service.py     # Core profanity detection
â”œâ”€â”€ data/                             # Data Layer
â”‚   â””â”€â”€ constants.py                  # Language mappings
â”œâ”€â”€ schemas/                          # Data Models
â”‚   â”œâ”€â”€ base.py                       # Base Pydantic models
â”‚   â”œâ”€â”€ requests.py                   # Request schemas
â”‚   â”œâ”€â”€ responses.py                  # Response schemas
â”‚   â””â”€â”€ moderation.py                 # Moderation schemas
â”œâ”€â”€ core/                            # Configuration
â”‚   â”œâ”€â”€ config.py                     # App settings
â”‚   â”œâ”€â”€ logger.py                     # Logging setup
â”‚   â””â”€â”€ middleware.py                 # CORS & middleware
â”œâ”€â”€ utils/                           # Utilities
â”‚   â””â”€â”€ helpers.py                    # Helper functions
â””â”€â”€ main.py                          # Application entry
```

---

## ğŸ“‹ Prerequisites

- **[Python 3.12+](https://www.python.org/)**
- **[UV Package Manager](https://github.com/astral-sh/uv)**
- **[Apache Kafka](https://kafka.apache.org/)** (optional - only needed if `KAFKA_ENABLED=true`)

### Install UV
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

---

## ğŸš€ Quick Start

### 1ï¸âƒ£ Clone & Setup
```bash
# Clone repository
git clone https://github.com/KB-iGOT/content-moderation-service.git
cd content-moderation-service

# Install dependencies
uv sync

# Activate environment
source .venv/bin/activate  # Linux/macOS
# .venv\Scripts\activate   # Windows
```

### 2ï¸âƒ£ Configure Environment
Create `.env` file:
```bash
cp .env.example .env
# Edit configuration as needed
```

### 3ï¸âƒ£ Start Service
```bash
uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
```

### 4ï¸âƒ£ Test API
```bash
curl -X POST "http://localhost:8000/api/v1/moderation/text" \
  -H "Content-Type: application/json" \
  -d '{"text": "Hello world!", "language": "en"}'
```

Service running at: http://localhost:8000

---

## âš™ï¸ Configuration

### ğŸ“Š Environment Variables

| Group | Variable | Type | Default | Description |
|-------|----------|------|---------|-------------|
| **API** | `PROJECT_NAME` | `string` | `"Content Moderation API"` | Application display name |
| | `PROJECT_VERSION` | `string` | `"1.0.0"` | API version identifier |
| | `API_V1_STR` | `string` | `"/api/v1"` | API version prefix |
| | `LOG_LEVEL` | `string` | `"INFO"` | Logging level (DEBUG, INFO, WARNING, ERROR) |
| **AI Models** | `ENGLISH_TRANSFORMER_MODEL` | `string` | `"unitary/toxic-bert"` | English profanity detection model |
| | `INDIC_TRANSFORMER_MODEL` | `string` | `"Hate-speech-CNERG/indic-abusive-allInOne-MuRIL"` | Indic languages model |
| | `LANGUAGE_DETECT_MODEL` | `string` | `"ZheYu03/xlm-r-langdetect-model"` | Language detection model |
| | `HF_HUB_OFFLINE` | `integer` | `1` | Prevent Hugging Face Hub calls |
| **Text Processing** | `MAX_TEXT_LENGTH` | `integer` | `500` | Max length before chunking |
| | `CHUNKING_ENABLED` | `boolean` | `true` | Enable automatic chunking |
| | `CHUNK_SIZE` | `integer` | `500` | Tokens per chunk |
| | `CHUNK_OVERLAP` | `integer` | `100` | Overlap between chunks |
| | `MAX_CHUNKS_PER_TEXT` | `integer` | `10` | Maximum chunks per text |
| **Kafka** | `KAFKA_ENABLED` | `boolean` | `true` | Enable Kafka streaming |
| | `KAFKA_BOOTSTRAP_SERVERS` | `string` | `"localhost:9092"` | Kafka broker connection |
| | `KAFKA_MODERATION_RESULTS_TOPIC` | `string` | `"dev.content.profanity"` | Results topic name |
| | `KAFKA_RETRIES` | `integer` | `3` | Retry attempts |
| | `KAFKA_RETRY_BACKOFF_MS` | `integer` | `100` | Retry delay (ms) |

### ğŸ“„ Example Configuration

```env
# API Settings
PROJECT_NAME="My Content Moderation API"
LOG_LEVEL=INFO
MAX_TEXT_LENGTH=1000

# Chunking Settings
CHUNKING_ENABLED=true
CHUNK_SIZE=512
CHUNK_OVERLAP=50
MAX_CHUNKS_PER_TEXT=20

# Kafka Settings (Optional)
KAFKA_ENABLED=true
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_MODERATION_RESULTS_TOPIC=content.moderation.results

# Hugging Face
HF_HUB_OFFLINE=1
```

---

## ğŸ“– API Documentation

### ğŸ“š Documentation Links

| Documentation | URL | Description |
|------------------|--------|----------------|
| **Interactive Docs** | `/docs` | Swagger UI with live testing |
| **ReDoc** | `/redoc` | Clean documentation format |
| **OpenAPI Schema** | `/api/v1/openapi.json` | Raw OpenAPI specification |

### ğŸ¯ Core Endpoints & Examples

#### ğŸ›¡ï¸ Profanity Detection
```http
POST /api/v1/moderation/text
```
**Purpose:** Analyze text for profanity content

**Request:**
```json
{
  "text": "Hello world, this is a test!",
  "language": "en",
  "metadata": {
    "user_id": "user123",
    "content_id": "post456",
    "source": "web_app"
  }
}
```

**Response:**
```json
{
  "status": "success",
  "message": "Profanity check completed",
  "responseData": {
    "text": "Hello world, this is a test!",
    "isProfane": false,
    "confidence": 99.88,
    "category": "Non-Profane",
    "detected_language": "en"
  }
}
```

**Chunked Analysis (Long Text):**
```json
{
  "status": "success",
  "message": "Profanity check completed using chunking (3 chunks)",
  "responseData": {
    "text": "Very long text that exceeds the maximum length...",
    "isProfane": true,
    "confidence": 87.5,
    "detected_language": "en",
    "category": "profane",
    "chunking_used": true,
    "total_chunks": 3,
    "profane_chunks": 1,
    "clean_chunks": 2,
    "aggregation_strategy": "priority_based",
    "chunk_statistics": {
      "total_processed": 3,
      "profane_detected": 1,
      "clean_detected": 2,
      "average_confidence": 75.2,
      "aggregation_rationale": "Profanity detected in any chunk takes priority"
    }
  }
}
```

#### ğŸ” Language Detection
```http
POST /api/v1/language/detect
```
**Purpose:** Identify text language

**Request:**
```json
{
  "text": "Hello, how are you today?"
}
```

**Response:**
```json
{
  "status": "success",
  "message": "Language detected successfully",
  "detected_language": "en",
  "language_name": "English",
  "confidence": 0.9999,
  "top_predictions": [
    {
      "language_code": "en",
      "language_name": "English",
      "confidence": 0.9999
    },
    {
      "language_code": "de",
      "language_name": "German",
      "confidence": 0.0001
    }
  ]
}
```

---

## ğŸ“¡ Kafka Integration

### ğŸ“¨ Event Structure

When `KAFKA_ENABLED=true`, the service emits events after each profanity check:

```json
{
  "request_data": {
    "text": "Input text for analysis",
    "language": "en",
    "metadata": {
      "user_id": "user123",
      "content_id": "post456",
      "source": "web_app"
    }
  },
  "response_data": {
    "status": "success",
    "message": "Profanity check completed",
    "responseData": {
      "isProfane": false,
      "confidence": 99.86,
      "category": "Non-Profane",
      "detected_language": "en",
      "model_used": "toxic-bert",
      "chunking_used": false
    }
  }
}
```

### ğŸ¯ Topic Configuration

| Topic | Purpose | Retention | Partitions |
|-------|---------|-----------|------------|
| `dev.content.profanity` | Profanity results | 7 days | 3 |

---

## ğŸ” Monitoring

### â¤ï¸ Health Monitoring

#### Health Check Endpoint
```http
GET /health
```

**Response:**
```json
{
  "status": "OK",
  "version": "1.0.0"
}
```

---

## ğŸ³ Docker Deployment

### ğŸš€ Quick Deploy

#### Build Image
```bash
docker build -t content-moderation-service .
```

#### Run Container
```bash
docker run -p 8000:8000 \
  -e KAFKA_ENABLED=false \
  -e LOG_LEVEL=INFO \
  content-moderation-service
```

#### With Environment File
```bash
docker run -p 8000:8000 \
  --env-file .env \
  content-moderation-service
```

#### Check Status
```bash
curl http://localhost:8000/health
```

---

## ğŸ¤ Contributing

### ğŸŒŸ We Welcome Contributions!

| Issues | Features | Documentation | Testing |
|-----------|-------------|------------------|------------|
| Bug reports | New features | Improve docs | Add tests |
| Performance issues | Model improvements | API examples | Coverage increase |

### ğŸ“‹ Contribution Process

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Make** your changes
4. **Add** tests for new functionality
5. **Update** documentation
6. **Ensure** all tests pass (`pytest`)
7. **Submit** a pull request

---

**Star this repository if you find it helpful!**

[â¬†ï¸ Back to Top](#-content-moderation-service)